---
title: "Regress√£o Linear"
author: Lucas Magalh√£es Ast
format: html
toc: true
---

# Regress√£o Linear: Simples e M√∫ltipla

## O que √© Regress√£o Linear?

A regress√£o linear √© uma t√©cnica estat√≠stica usada para modelar a **rela√ß√£o entre vari√°veis**. O objetivo √© **prever ou explicar** uma vari√°vel dependente $y$ com base em uma ou mais vari√°veis independentes $x$.

---

## Regress√£o Linear Simples

### Defini√ß√£o

Modela a rela√ß√£o entre **duas vari√°veis**:  
- Uma vari√°vel dependente $y$  
- Uma vari√°vel independente $x$

---

### F√≥rmula

$$
\hat{y} = \beta_0 + \beta_1 x
$$

- $\hat{y}$: valor previsto  
- $\beta_0$: intercepto  
- $\beta_1$: coeficiente angular  
- $x$: vari√°vel explicativa  

---

## O que √© o Coeficiente Angular ($\beta_1$)?

√â o n√∫mero que indica **quanto a vari√°vel $y$ varia** quando $x$ aumenta em uma unidade.

- Se $\beta_1 = 3$, cada aumento de 1 unidade em $x$ causa aumento de 3 unidades em $y$.
- Se $\beta_1 < 0$, a rela√ß√£o √© decrescente.

---

## Exemplo de Regress√£o Linear Simples

Suponha a fun√ß√£o:

$$
y = 2 + 3x
$$

| x | y |
|---|---|
| 0 | 2 |
| 1 | 5 |
| 2 | 8 |

- Intercepto $\beta_0 = 2$
- Inclina√ß√£o $\beta_1 = 3$
---

## C√°lculo dos Coeficientes

O m√©todo dos m√≠nimos quadrados calcula os coeficientes que **minimizam a soma dos quadrados dos erros**.

F√≥rmula fo coeficiente angular:
$$
\beta_1 = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}
$$

F√≥rmula do intercepto:
$$
\beta_0 = \bar{y} - \beta_1 \bar{x}
$$

### Passos do MQO

Queremos encontrar os coeficientes $\beta_0$ e $\beta_1$ que melhor ajustam o modelo:

$$
\hat{y} = \beta_0 + \beta_1 x
$$

#### Calcular as m√©dias

$$
\bar{x} = \frac{0 + 1 + 2}{3} = 1\\
\bar{y} = \frac{2 + 5 + 8}{3} = 5
$$

#### Calcular o coeficiente angular ($\beta_1$)

$$
\beta_1 = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}
$$

Montando a tabela:

| $x_i$ | $y_i$ | $x_i - \bar{x}$ | $y_i - \bar{y}$ | $(x_i - \bar{x})(y_i - \bar{y})$ | $(x_i - \bar{x})^2$ |
|------|------|------------------|------------------|----------------------------------|---------------------|
| 0    | 2    | -1               | -3               | 3                                | 1                   |
| 1    | 5    | 0                | 0                | 0                                | 0                   |
| 2    | 8    | 1                | 3                | 3                                | 1                   |

Somando:

$$
\beta_1 = \frac{3 + 0 + 3}{1 + 0 + 1} = \frac{6}{2} = 3
$$

#### Calcular o intercepto ($\beta_0$)

$$
\beta_0 = \bar{y} - \beta_1 \bar{x} = 5 - 3 \cdot 1 = 2
$$

---

### Resultado:

A equa√ß√£o estimada √©:

$$
\hat{y} = 2 + 3x
$$

- Intercepto $\beta_0 = 2$
- Inclina√ß√£o $\beta_1 = 3$


---

## Exemplo Pr√°tico em Python (Regress√£o Linear Simples)
```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Dados simulados
x = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([2, 4, 5, 4, 5])

# Criando e ajustando o modelo
modelo = LinearRegression()
modelo.fit(x, y)

# Coeficientes
print("Intercepto (b0):", modelo.intercept_)
print("Coeficiente angular (b1):", modelo.coef_[0])

# Previs√µes
y_pred = modelo.predict(x)

# Gr√°fico
plt.scatter(x, y, color='blue', label='Dados reais')
plt.plot(x, y_pred, color='red', label='Regress√£o linear')
plt.title("Regress√£o Linear Simples")
plt.xlabel("x")
plt.ylabel("y")
plt.legend()
plt.grid(True)
plt.show()
```

## Regress√£o Linear M√∫ltipla

### Defini√ß√£o

Estende a regress√£o simples para incluir **mais de uma vari√°vel explicativa**.

### F√≥rmula

$$
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n
$$

- Cada $\beta_i$ representa o **efeito isolado de $x_i$** sobre $y$, mantendo os outros fixos.

### Exemplo:
Previs√£o do pre√ßo de um carro com base em:
- $x_1$: quilometragem
- $x_2$: ano
- $x_3$: tipo de combust√≠vel

$$
\hat{y} = 50000 - 0.05x_1 + 300x_2 + 1000x_3
$$

###  Forma matricial do MQO

Para m√∫ltiplas vari√°veis, usamos a f√≥rmula matricial:

$$
\hat{\beta} = (X^\top X)^{-1} X^\top y
$$

Onde:

- $X$: matriz de vari√°veis (com uma coluna de 1s para o intercepto)
- $y$: vetor de respostas
- $\hat{\beta}$: vetor de coeficientes $(\beta_0, \beta_1, \beta_2, \beta_3)$

---

### Suponha os seguintes dados:

| $x_1$ (km) | $x_2$ (ano) | $x_3$ (comb.) | $y$ (pre√ßo) |
|------------|-------------|---------------|-------------|
| 20000      | 2020        | 0             | 56000       |
| 40000      | 2019        | 1             | 55200       |
| 10000      | 2021        | 1             | 59000       |

---

### Montando as matrizes

$$
X =
\begin{bmatrix}
1 & 20000 & 2020 & 0 \\
1 & 40000 & 2019 & 1 \\
1 & 10000 & 2021 & 1 \\
\end{bmatrix},
\quad
y =
\begin{bmatrix}
56000 \\
55200 \\
59000 \\
\end{bmatrix}
$$

---

### Aplicando o MQO

Usamos a f√≥rmula:

$$
\hat{\beta} = (X^\top X)^{-1} X^\top y
$$

O c√°lculo envolve:

1. Multiplicar $X^\top X$
2. Inverter $(X^\top X)$
3. Multiplicar pelo vetor $X^\top y$

Esse processo gera os coeficientes estimados:

$$
\hat{\beta} =
\begin{bmatrix}
50000 \\
-0.05 \\
300 \\
1000 \\
\end{bmatrix}
$$

---

### Resultado:

A equa√ß√£o estimada da regress√£o m√∫ltipla √©:

$$
\hat{y} = 50000 - 0.05x_1 + 300x_2 + 1000x_3
$$

---

### üí° Observa√ß√£o:

Esse modelo diz, por exemplo, que:
- Cada quil√¥metro rodado reduz o valor do carro em R$ 0,05
- Cada ano de fabrica√ß√£o a mais aumenta o valor em R$ 300
- Ve√≠culos a √°lcool valem R$ 1.000 a mais, em m√©dia, que os a gasolina (assumindo $x_3 = 1$)

---

## Exemplo Pr√°tico em Python (Regress√£o Linear M√∫ltipla)
```{python}
import numpy as np
from sklearn.linear_model import LinearRegression

# Vari√°veis explicativas (2 vari√°veis: x1 e x2)
X = np.array([
    [1, 2],
    [2, 1],
    [3, 3],
    [4, 5],
    [5, 4]
])

# Vari√°vel resposta
y = np.array([5, 6, 9, 11, 10])

# Ajustando o modelo
modelo = LinearRegression()
modelo.fit(X, y)

# Resultados
print("Intercepto (b0):", modelo.intercept_)
print("Coeficientes (b1, b2):", modelo.coef_)

# Previs√µes
y_pred = modelo.predict(X)
print("Valores previstos:", y_pred)
```

---
## Interpreta√ß√£o e Limita√ß√µes Preditivas da Regress√£o Linear

A regress√£o linear √© frequentemente usada como modelo preditivo, mas √© importante entender suas reais capacidades e limita√ß√µes.

### O que a Regress√£o Linear faz bem?

A regress√£o linear capta a tend√™ncia m√©dia de uma vari√°vel resposta $y$ em fun√ß√£o de uma ou mais vari√°veis explicativas $x$.

Ela √© excelente para:

- **Modelar rela√ß√µes lineares simples**
- **Observar comportamentos m√©dios**
- **Interpretar coeficientes** (quanto uma vari√°vel impacta a outra, em m√©dia)
- **Avalia√ß√£o descritiva e inferencial**

---

### Como modelo preditivo?

A regress√£o linear n√£o √© robusta como modelo preditivo em situa√ß√µes reais com dados complexos. Ela assume uma s√©rie de condi√ß√µes ideais:

1. Linearidade da rela√ß√£o entre $x$ e $y$
2. Homocedasticidade (vari√¢ncia constante dos res√≠duos)
3. Normalidade dos erros
4. Aus√™ncia de multicolinearidade (na regress√£o m√∫ltipla)

Quando essas condi√ß√µes n√£o s√£o atendidas, a capacidade preditiva **cai drasticamente.

---

### Forma correta de interpretar

- Evite dizer que:  
  > ‚ÄúRegress√£o linear √© um modelo s√≥lido de previs√£o.‚Äù

- Prefira dizer:  
  > ‚ÄúA regress√£o linear √© uma ferramenta √∫til para capturar a tend√™ncia m√©dia de uma vari√°vel resposta com base em vari√°veis explicativas, mas possui limita√ß√µes como modelo preditivo, especialmente em cen√°rios n√£o-lineares ou com alta variabilidade.‚Äù

---

### Quando usar regress√£o linear?

Use regress√£o linear quando seu objetivo for:

- **Entender uma rela√ß√£o m√©dia** entre vari√°veis
- **Testar hip√≥teses estat√≠sticas**
- **Explicar varia√ß√µes m√©dias** em $y$
- **Prever dentro de um intervalo bem comportado**, onde os dados sigam aproximadamente uma tend√™ncia linear

---

### Modelos alternativos para previs√£o robusta

Se seu objetivo √© previs√£o com alta acur√°cia, considere modelos mais sofisticados, como:

- Regress√£o polinomial
- √Årvores de decis√£o e Random Forest
- Regress√£o Lasso/Ridge
- Modelos de s√©ries temporais (ARIMA, Prophet)
- Redes neurais (deep learning)

---

### Conclus√£o

A regress√£o linear √© uma excelente ferramenta para modelar tend√™ncias** e compreender rela√ß√µes entre vari√°veis, mas deve ser usada com cautela como modelo preditivo em contextos reais complexos.
